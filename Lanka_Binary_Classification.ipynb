{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyHSICLasso import HSICLasso\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and identify the classes\n",
    "static_fc_data = scipy.io.loadmat('Static_functional_connectivity_ptsd_dc_filt.mat')\n",
    "sfc_controls = static_fc_data['conn_sfc_dc_filt_controls']  # (125, 125, 56)\n",
    "sfc_ptsd = static_fc_data['conn_sfc_dc_filt_ptsd']         # (125, 125, 34)\n",
    "sfc_pcsptsd = static_fc_data['conn_sfc_dc_filt_pcsptsd']   # (125, 125, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the upper triangular part of the matrices \n",
    "def extract_upper_triangle(connectivity_matrices):\n",
    "    \"\"\"Extract upper triangle (excluding diagonal) from connectivity matrices\"\"\"\n",
    "    n_regions = connectivity_matrices.shape[0]\n",
    "    n_subjects = connectivity_matrices.shape[2]\n",
    "   \n",
    "    # Get upper triangle indices\n",
    "    upper_idx = np.triu_indices(n_regions, k=1)\n",
    "   \n",
    "    # Extract features for each subject\n",
    "    features = np.zeros((n_subjects, len(upper_idx[0])))\n",
    "    for i in range(n_subjects):\n",
    "        features[i] = connectivity_matrices[upper_idx[0], upper_idx[1], i]\n",
    "   \n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "controls_features = extract_upper_triangle(sfc_controls)  # (56, 7750)\n",
    "ptsd_features = extract_upper_triangle(sfc_ptsd)          # (34, 7750)\n",
    "pcsptsd_features = extract_upper_triangle(sfc_pcsptsd)    # (84, 7750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine groups and create labels\n",
    "X = np.vstack([controls_features, ptsd_features, pcsptsd_features])  # (174, 7750)\n",
    "y = np.hstack([\n",
    "    np.zeros(controls_features.shape[0]),      # 0 = controls\n",
    "    np.ones(ptsd_features.shape[0]),           # 1 = PTSD & PTSD+PCS\n",
    "    np.ones(pcsptsd_features.shape[0])       \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (Without stratified sampling to replicate the reference paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (139, 7750), Testing set: (35, 7750)\n"
     ]
    }
   ],
   "source": [
    "# Standardizing features after split to avoid potential data leakage and overfitting\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature names (node pairs)\n",
    "n_regions = sfc_controls.shape[0]\n",
    "upper_idx = np.triu_indices(n_regions, k=1)\n",
    "feature_names = [f\"Region_{i+1}_{j+1}\" for i, j in zip(upper_idx[0], upper_idx[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSIC Lasso for binary classification\n",
    "# First convert labels to one-hot encoding\n",
    "n_classes = len(np.unique(y))\n",
    "y_train_onehot = np.zeros((len(y_train), n_classes))\n",
    "for i in range(n_classes):\n",
    "    y_train_onehot[:, i] = (y_train == i).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing HSIC Lasso for Class 0\n",
      "Block HSIC Lasso B = 139.\n",
      "M set to 1.\n",
      "Using Gaussian kernel for the features, Delta kernel for the outcomes.\n",
      "Top 200 features for Class 0:\n",
      "  Region_94_107: 0.1139\n",
      "  Region_32_67: 0.1061\n",
      "  Region_97_125: 0.0713\n",
      "  Region_72_105: 0.0642\n",
      "  Region_88_94: 0.0497\n",
      "  Region_8_31: 0.0439\n",
      "  Region_95_110: 0.0418\n",
      "  Region_21_56: 0.0398\n",
      "  Region_25_77: 0.0384\n",
      "  Region_50_100: 0.0373\n",
      "  Region_11_116: 0.0364\n",
      "  Region_63_105: 0.0355\n",
      "  Region_19_114: 0.0340\n",
      "  Region_38_56: 0.0339\n",
      "  Region_82_104: 0.0332\n",
      "  Region_50_104: 0.0319\n",
      "  Region_13_23: 0.0316\n",
      "  Region_62_116: 0.0311\n",
      "  Region_25_112: 0.0294\n",
      "  Region_87_122: 0.0279\n",
      "  Region_77_107: 0.0275\n",
      "  Region_26_96: 0.0260\n",
      "  Region_92_104: 0.0255\n",
      "  Region_77_104: 0.0252\n",
      "  Region_65_103: 0.0246\n",
      "  Region_15_64: 0.0244\n",
      "  Region_6_116: 0.0241\n",
      "  Region_13_17: 0.0236\n",
      "  Region_21_64: 0.0233\n",
      "  Region_9_120: 0.0223\n",
      "  Region_82_106: 0.0223\n",
      "  Region_16_31: 0.0217\n",
      "  Region_46_47: 0.0211\n",
      "  Region_48_49: 0.0211\n",
      "  Region_68_125: 0.0205\n",
      "  Region_50_118: 0.0204\n",
      "  Region_21_33: 0.0192\n",
      "  Region_96_107: 0.0190\n",
      "  Region_5_32: 0.0187\n",
      "  Region_61_77: 0.0185\n",
      "  Region_12_103: 0.0184\n",
      "  Region_5_12: 0.0183\n",
      "  Region_3_78: 0.0173\n",
      "  Region_49_67: 0.0169\n",
      "  Region_6_63: 0.0168\n",
      "  Region_54_94: 0.0167\n",
      "  Region_24_112: 0.0163\n",
      "  Region_77_86: 0.0158\n",
      "  Region_79_83: 0.0148\n",
      "  Region_34_118: 0.0146\n",
      "  Region_71_84: 0.0145\n",
      "  Region_20_27: 0.0141\n",
      "  Region_44_112: 0.0134\n",
      "  Region_23_86: 0.0133\n",
      "  Region_9_110: 0.0133\n",
      "  Region_23_96: 0.0132\n",
      "  Region_52_64: 0.0131\n",
      "  Region_49_51: 0.0126\n",
      "  Region_46_106: 0.0126\n",
      "  Region_46_100: 0.0125\n",
      "  Region_118_124: 0.0125\n",
      "  Region_86_125: 0.0121\n",
      "  Region_3_37: 0.0115\n",
      "  Region_26_43: 0.0114\n",
      "  Region_33_105: 0.0112\n",
      "  Region_40_96: 0.0109\n",
      "  Region_57_77: 0.0103\n",
      "  Region_33_84: 0.0101\n",
      "  Region_32_122: 0.0100\n",
      "  Region_52_107: 0.0100\n",
      "  Region_3_33: 0.0099\n",
      "  Region_64_88: 0.0097\n",
      "  Region_29_50: 0.0097\n",
      "  Region_107_123: 0.0093\n",
      "  Region_62_69: 0.0092\n",
      "  Region_7_21: 0.0088\n",
      "  Region_11_95: 0.0086\n",
      "  Region_92_106: 0.0077\n",
      "  Region_16_111: 0.0076\n",
      "  Region_99_113: 0.0073\n",
      "  Region_7_56: 0.0073\n",
      "  Region_12_114: 0.0071\n",
      "  Region_17_30: 0.0066\n",
      "  Region_64_121: 0.0065\n",
      "  Region_11_99: 0.0063\n",
      "  Region_35_115: 0.0062\n",
      "  Region_47_50: 0.0060\n",
      "  Region_8_82: 0.0058\n",
      "  Region_29_81: 0.0056\n",
      "  Region_62_105: 0.0055\n",
      "  Region_15_102: 0.0055\n",
      "  Region_9_94: 0.0054\n",
      "  Region_99_121: 0.0054\n",
      "  Region_9_57: 0.0052\n",
      "  Region_57_94: 0.0052\n",
      "  Region_13_115: 0.0050\n",
      "  Region_60_83: 0.0050\n",
      "  Region_35_48: 0.0047\n",
      "  Region_67_83: 0.0045\n",
      "  Region_58_84: 0.0045\n",
      "  Region_15_47: 0.0041\n",
      "  Region_23_87: 0.0040\n",
      "  Region_32_55: 0.0038\n",
      "  Region_21_37: 0.0036\n",
      "  Region_26_94: 0.0035\n",
      "  Region_63_101: 0.0032\n",
      "  Region_13_46: 0.0029\n",
      "  Region_32_79: 0.0028\n",
      "  Region_45_118: 0.0026\n",
      "  Region_8_15: 0.0025\n",
      "  Region_11_71: 0.0024\n",
      "  Region_46_111: 0.0023\n",
      "  Region_29_32: 0.0020\n",
      "  Region_43_46: 0.0020\n",
      "  Region_100_110: 0.0019\n",
      "  Region_17_61: 0.0017\n",
      "  Region_67_86: 0.0016\n",
      "  Region_68_78: 0.0016\n",
      "  Region_46_104: 0.0016\n",
      "  Region_48_110: 0.0015\n",
      "  Region_89_104: 0.0014\n",
      "  Region_33_64: 0.0013\n",
      "  Region_52_72: 0.0013\n",
      "  Region_58_71: 0.0008\n",
      "  Region_25_115: 0.0008\n",
      "  Region_66_79: 0.0008\n",
      "  Region_31_98: 0.0005\n",
      "  Region_19_97: 0.0002\n",
      "  Region_18_34: 0.0000\n",
      "  Region_31_114: 0.0000\n",
      "  Region_2_86: 0.0000\n",
      "\n",
      "Performing HSIC Lasso for Class 1\n",
      "Block HSIC Lasso B = 139.\n",
      "M set to 1.\n",
      "Using Gaussian kernel for the features, Delta kernel for the outcomes.\n",
      "Top 200 features for Class 1:\n",
      "  Region_94_107: 0.1139\n",
      "  Region_32_67: 0.1061\n",
      "  Region_97_125: 0.0713\n",
      "  Region_72_105: 0.0642\n",
      "  Region_88_94: 0.0497\n",
      "  Region_8_31: 0.0439\n",
      "  Region_95_110: 0.0418\n",
      "  Region_21_56: 0.0398\n",
      "  Region_25_77: 0.0384\n",
      "  Region_50_100: 0.0373\n",
      "  Region_11_116: 0.0364\n",
      "  Region_63_105: 0.0355\n",
      "  Region_19_114: 0.0340\n",
      "  Region_38_56: 0.0339\n",
      "  Region_82_104: 0.0332\n",
      "  Region_50_104: 0.0319\n",
      "  Region_13_23: 0.0316\n",
      "  Region_62_116: 0.0311\n",
      "  Region_25_112: 0.0294\n",
      "  Region_87_122: 0.0279\n",
      "  Region_77_107: 0.0275\n",
      "  Region_26_96: 0.0260\n",
      "  Region_92_104: 0.0255\n",
      "  Region_77_104: 0.0252\n",
      "  Region_65_103: 0.0246\n",
      "  Region_15_64: 0.0244\n",
      "  Region_6_116: 0.0241\n",
      "  Region_13_17: 0.0236\n",
      "  Region_21_64: 0.0233\n",
      "  Region_9_120: 0.0223\n",
      "  Region_82_106: 0.0223\n",
      "  Region_16_31: 0.0217\n",
      "  Region_46_47: 0.0211\n",
      "  Region_48_49: 0.0211\n",
      "  Region_68_125: 0.0205\n",
      "  Region_50_118: 0.0204\n",
      "  Region_21_33: 0.0192\n",
      "  Region_96_107: 0.0190\n",
      "  Region_5_32: 0.0187\n",
      "  Region_61_77: 0.0185\n",
      "  Region_12_103: 0.0184\n",
      "  Region_5_12: 0.0183\n",
      "  Region_3_78: 0.0173\n",
      "  Region_49_67: 0.0169\n",
      "  Region_6_63: 0.0168\n",
      "  Region_54_94: 0.0167\n",
      "  Region_24_112: 0.0163\n",
      "  Region_77_86: 0.0158\n",
      "  Region_79_83: 0.0148\n",
      "  Region_34_118: 0.0146\n",
      "  Region_71_84: 0.0145\n",
      "  Region_20_27: 0.0141\n",
      "  Region_44_112: 0.0134\n",
      "  Region_23_86: 0.0133\n",
      "  Region_9_110: 0.0133\n",
      "  Region_23_96: 0.0132\n",
      "  Region_52_64: 0.0131\n",
      "  Region_49_51: 0.0126\n",
      "  Region_46_106: 0.0126\n",
      "  Region_46_100: 0.0125\n",
      "  Region_118_124: 0.0125\n",
      "  Region_86_125: 0.0121\n",
      "  Region_3_37: 0.0115\n",
      "  Region_26_43: 0.0114\n",
      "  Region_33_105: 0.0112\n",
      "  Region_40_96: 0.0109\n",
      "  Region_57_77: 0.0103\n",
      "  Region_33_84: 0.0101\n",
      "  Region_32_122: 0.0100\n",
      "  Region_52_107: 0.0100\n",
      "  Region_3_33: 0.0099\n",
      "  Region_64_88: 0.0097\n",
      "  Region_29_50: 0.0097\n",
      "  Region_107_123: 0.0093\n",
      "  Region_62_69: 0.0092\n",
      "  Region_7_21: 0.0088\n",
      "  Region_11_95: 0.0086\n",
      "  Region_92_106: 0.0077\n",
      "  Region_16_111: 0.0076\n",
      "  Region_99_113: 0.0073\n",
      "  Region_7_56: 0.0073\n",
      "  Region_12_114: 0.0071\n",
      "  Region_17_30: 0.0066\n",
      "  Region_64_121: 0.0065\n",
      "  Region_11_99: 0.0063\n",
      "  Region_35_115: 0.0062\n",
      "  Region_47_50: 0.0060\n",
      "  Region_8_82: 0.0058\n",
      "  Region_29_81: 0.0056\n",
      "  Region_62_105: 0.0055\n",
      "  Region_15_102: 0.0055\n",
      "  Region_9_94: 0.0054\n",
      "  Region_99_121: 0.0054\n",
      "  Region_9_57: 0.0052\n",
      "  Region_57_94: 0.0052\n",
      "  Region_13_115: 0.0050\n",
      "  Region_60_83: 0.0050\n",
      "  Region_35_48: 0.0047\n",
      "  Region_67_83: 0.0045\n",
      "  Region_58_84: 0.0045\n",
      "  Region_15_47: 0.0041\n",
      "  Region_23_87: 0.0040\n",
      "  Region_32_55: 0.0038\n",
      "  Region_21_37: 0.0036\n",
      "  Region_26_94: 0.0035\n",
      "  Region_63_101: 0.0032\n",
      "  Region_13_46: 0.0029\n",
      "  Region_32_79: 0.0028\n",
      "  Region_45_118: 0.0026\n",
      "  Region_8_15: 0.0025\n",
      "  Region_11_71: 0.0024\n",
      "  Region_46_111: 0.0023\n",
      "  Region_29_32: 0.0020\n",
      "  Region_43_46: 0.0020\n",
      "  Region_100_110: 0.0019\n",
      "  Region_17_61: 0.0017\n",
      "  Region_67_86: 0.0016\n",
      "  Region_68_78: 0.0016\n",
      "  Region_46_104: 0.0016\n",
      "  Region_48_110: 0.0015\n",
      "  Region_89_104: 0.0014\n",
      "  Region_33_64: 0.0013\n",
      "  Region_52_72: 0.0013\n",
      "  Region_58_71: 0.0008\n",
      "  Region_25_115: 0.0008\n",
      "  Region_66_79: 0.0008\n",
      "  Region_31_98: 0.0005\n",
      "  Region_19_97: 0.0002\n",
      "  Region_18_34: 0.0000\n",
      "  Region_31_114: 0.0000\n",
      "  Region_2_86: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Number of top features to select per class\n",
    "n_select = 200\n",
    "\n",
    "# Initialize HSIC Lasso\n",
    "hsic_lasso = HSICLasso()\n",
    "\n",
    "# Store selected features for each class\n",
    "all_selected_features = {}\n",
    "selected_feature_indices = set()\n",
    "\n",
    "for class_idx in range(n_classes):\n",
    "    print(f\"\\nPerforming HSIC Lasso for Class {class_idx}\")\n",
    "    \n",
    "    # Use the current class column as target\n",
    "    y_class = y_train_onehot[:, class_idx]\n",
    "    \n",
    "    # Fit HSIC Lasso\n",
    "    hsic_lasso.input(X_train_scaled, y_class)\n",
    "    hsic_lasso.classification(num_feat=n_select, B=139)\n",
    "    \n",
    "    # Get selected feature indices\n",
    "    selected = hsic_lasso.get_index()\n",
    "    selected_feature_indices.update(selected)\n",
    "    \n",
    "    # Get feature scores\n",
    "    scores = hsic_lasso.get_index_score()\n",
    "    \n",
    "    # Store selected features and their scores\n",
    "    all_selected_features[f\"Class_{class_idx}\"] = {\n",
    "        'features': [feature_names[idx] for idx in selected],\n",
    "        'indices': selected,\n",
    "        'scores': scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Top {n_select} features for Class {class_idx}:\")\n",
    "    for i, idx in enumerate(selected):\n",
    "        print(f\"  {feature_names[idx]}: {scores[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features unique to each class:\n",
      "Class 0: 0\n",
      "Class 1: 0\n",
      "\n",
      "Features shared between pairs:\n",
      "Class 0 and 1: 131\n",
      "Total unique features: 131\n"
     ]
    }
   ],
   "source": [
    "def analyze_feature_distribution(all_selected_features, n_classes):\n",
    "    # Create dictionary to store feature occurrences\n",
    "    feature_occurrence = {}\n",
    "    \n",
    "    # Count occurrences of each feature across classes\n",
    "    for class_idx in range(n_classes):\n",
    "        features = all_selected_features[f\"Class_{class_idx}\"]['features']\n",
    "        for feature in features:\n",
    "            if feature not in feature_occurrence:\n",
    "                feature_occurrence[feature] = []\n",
    "            feature_occurrence[feature].append(class_idx)\n",
    "    \n",
    "    # Count features by occurrence \n",
    "    class_specific = {i: 0 for i in range(n_classes)}  # Features unique to each class\n",
    "    class_pairs = {(i, j): 0 for i in range(n_classes) for j in range(i+1, n_classes)}  # Features shared by pairs\n",
    "    #shared_by_all = 0  # Features shared by all classes\n",
    "    \n",
    "    for feat, classes in feature_occurrence.items():\n",
    "        if len(classes) == 1:\n",
    "            class_specific[classes[0]] += 1\n",
    "        elif len(classes) == 2:\n",
    "            class_pairs[tuple(sorted(classes))] += 1\n",
    "    \n",
    "    # Print numerical summary\n",
    "    print(\"\\nFeatures unique to each class:\")\n",
    "    for class_idx, count in class_specific.items():\n",
    "        print(f\"Class {class_idx}: {count}\")\n",
    "        \n",
    "    print(\"\\nFeatures shared between pairs:\")\n",
    "    for (c1, c2), count in class_pairs.items():\n",
    "        print(f\"Class {c1} and {c2}: {count}\")\n",
    "        \n",
    "    print(f\"Total unique features: {len(feature_occurrence)}\")\n",
    "\n",
    "# Run the analysis\n",
    "feature_analysis = analyze_feature_distribution(all_selected_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "0        Random Forest  0.800000   0.851852  0.800000  0.784459\n",
      "1                  SVM  0.914286   0.925466  0.914286  0.912514\n",
      "2                  MLP  0.885714   0.889111  0.885714  0.884354\n",
      "3  Logistic Regression  0.914286   0.925466  0.914286  0.912514\n",
      "4  K-Nearest Neighbors  0.885714   0.889111  0.885714  0.884354\n",
      "5    Gradient Boosting  0.800000   0.851852  0.800000  0.784459\n",
      "6              XGBoost  0.771429   0.836735  0.771429  0.748918\n"
     ]
    }
   ],
   "source": [
    "# Get all unique selected features\n",
    "all_features = []\n",
    "for class_data in all_selected_features.values():\n",
    "    all_features.extend(class_data['features'])\n",
    "unique_features = list(set(all_features))\n",
    "\n",
    "# Extract unique selected features\n",
    "unique_selected_indices = list(selected_feature_indices)\n",
    "X_train_selected = X_train_scaled[:, unique_selected_indices]\n",
    "X_test_selected = X_test_scaled[:, unique_selected_indices]\n",
    "\n",
    "# Split into train/validation/test\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_selected, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'MLP': MLPClassifier(max_iter=500, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Random Forest': {'n_estimators': [50, 100], 'max_depth': [None, 10]},\n",
    "    'SVM': {'C': [0.1, 1], 'kernel': ['linear', 'rbf']},\n",
    "    'MLP': {'hidden_layer_sizes': [(50,), (100,)], 'alpha': [0.0001, 0.001]},\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
    "    'K-Nearest Neighbors': {'n_neighbors': [3, 5]},\n",
    "    'Gradient Boosting': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    'XGBoost': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "# Train and validate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_final, y_train_final)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Validation evaluation\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': best_model,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "\n",
    "results_table = []\n",
    "\n",
    "# Evaluate all models on the test set\n",
    "for name in models:\n",
    "    model = results[name]['model'].fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results_table.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_table)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
