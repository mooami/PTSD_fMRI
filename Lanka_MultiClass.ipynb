{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyHSICLasso import HSICLasso\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and identify the classes\n",
    "static_fc_data = scipy.io.loadmat('Static_functional_connectivity_ptsd_dc_filt.mat')\n",
    "sfc_controls = static_fc_data['conn_sfc_dc_filt_controls']  # (125, 125, 56)\n",
    "sfc_ptsd = static_fc_data['conn_sfc_dc_filt_ptsd']         # (125, 125, 34)\n",
    "sfc_pcsptsd = static_fc_data['conn_sfc_dc_filt_pcsptsd']   # (125, 125, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract upper triangle (excluding diagonal) from connectivity matrices\n",
    "def extract_upper_triangle(connectivity_matrices):\n",
    "    n_regions = connectivity_matrices.shape[0]\n",
    "    n_subjects = connectivity_matrices.shape[2]\n",
    "   \n",
    "    # Get upper triangle indices\n",
    "    upper_idx = np.triu_indices(n_regions, k=1)\n",
    "   \n",
    "    # Extract features for each subject\n",
    "    features = np.zeros((n_subjects, len(upper_idx[0])))\n",
    "    for i in range(n_subjects):\n",
    "        features[i] = connectivity_matrices[upper_idx[0], upper_idx[1], i]\n",
    "   \n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "controls_features = extract_upper_triangle(sfc_controls)  # (56, 7750)\n",
    "ptsd_features = extract_upper_triangle(sfc_ptsd)          # (34, 7750)\n",
    "pcsptsd_features = extract_upper_triangle(sfc_pcsptsd)    # (84, 7750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine groups and create labels\n",
    "X = np.vstack([controls_features, ptsd_features, pcsptsd_features])  # (174, 7750)\n",
    "y = np.hstack([\n",
    "    np.zeros(controls_features.shape[0]),      # 0 = controls\n",
    "    np.ones(ptsd_features.shape[0]),           # 1 = PTSD\n",
    "    2*np.ones(pcsptsd_features.shape[0])       # 2 = PCS-PTSD\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (Without stratified sampling to replicate the reference paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (139, 7750), Testing set: (35, 7750)\n"
     ]
    }
   ],
   "source": [
    "# Standardizing features after split to avoid potential data leakage and overfitting\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature names (node pairs)\n",
    "n_regions = sfc_controls.shape[0]\n",
    "upper_idx = np.triu_indices(n_regions, k=1)\n",
    "feature_names = [f\"Region_{i+1}_{j+1}\" for i, j in zip(upper_idx[0], upper_idx[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSIC Lasso for multi-class classification\n",
    "# We'll perform one-vs-rest HSIC Lasso for each class\n",
    "# First convert labels to one-hot encoding\n",
    "n_classes = len(np.unique(y))\n",
    "y_train_onehot = np.zeros((len(y_train), n_classes))\n",
    "for i in range(n_classes):\n",
    "    y_train_onehot[:, i] = (y_train == i).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing HSIC Lasso for Class 0\n",
      "Block HSIC Lasso B = 20.\n",
      "M set to 3.\n",
      "Using Gaussian kernel for the features, Delta kernel for the outcomes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyHSICLasso\\api.py:107: RuntimeWarning: B 20 must be an exact divisor of the number of samples 139. Number of blocks 6.95 will be approximated to 6.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 200 features for Class 0:\n",
      "  Region_94_107: 0.0773\n",
      "  Region_50_100: 0.0605\n",
      "  Region_32_67: 0.0575\n",
      "  Region_65_103: 0.0493\n",
      "  Region_87_122: 0.0483\n",
      "  Region_97_125: 0.0384\n",
      "  Region_82_106: 0.0379\n",
      "  Region_43_112: 0.0362\n",
      "  Region_72_105: 0.0324\n",
      "  Region_44_112: 0.0315\n",
      "  Region_14_122: 0.0298\n",
      "  Region_84_106: 0.0297\n",
      "  Region_62_116: 0.0270\n",
      "  Region_50_104: 0.0265\n",
      "  Region_77_86: 0.0257\n",
      "  Region_8_31: 0.0256\n",
      "  Region_19_31: 0.0219\n",
      "  Region_68_125: 0.0215\n",
      "  Region_57_104: 0.0208\n",
      "  Region_61_77: 0.0182\n",
      "  Region_3_56: 0.0167\n",
      "  Region_25_112: 0.0161\n",
      "  Region_57_100: 0.0148\n",
      "  Region_5_32: 0.0148\n",
      "  Region_32_121: 0.0144\n",
      "  Region_16_31: 0.0144\n",
      "  Region_21_64: 0.0136\n",
      "  Region_57_77: 0.0134\n",
      "  Region_68_78: 0.0116\n",
      "  Region_94_97: 0.0109\n",
      "  Region_13_23: 0.0108\n",
      "  Region_15_64: 0.0107\n",
      "  Region_50_107: 0.0103\n",
      "  Region_82_104: 0.0099\n",
      "  Region_9_120: 0.0098\n",
      "  Region_13_42: 0.0097\n",
      "  Region_13_115: 0.0097\n",
      "  Region_6_63: 0.0096\n",
      "  Region_95_110: 0.0096\n",
      "  Region_19_79: 0.0095\n",
      "  Region_13_17: 0.0088\n",
      "  Region_48_49: 0.0086\n",
      "  Region_11_116: 0.0084\n",
      "  Region_107_123: 0.0084\n",
      "  Region_19_114: 0.0083\n",
      "  Region_6_30: 0.0078\n",
      "  Region_67_86: 0.0068\n",
      "  Region_72_125: 0.0065\n",
      "  Region_56_74: 0.0061\n",
      "  Region_50_77: 0.0059\n",
      "  Region_32_79: 0.0055\n",
      "  Region_79_81: 0.0053\n",
      "  Region_35_115: 0.0052\n",
      "  Region_27_89: 0.0052\n",
      "  Region_52_72: 0.0050\n",
      "  Region_32_40: 0.0048\n",
      "  Region_17_97: 0.0048\n",
      "  Region_2_64: 0.0048\n",
      "  Region_31_46: 0.0046\n",
      "  Region_25_36: 0.0041\n",
      "  Region_72_94: 0.0039\n",
      "  Region_40_50: 0.0038\n",
      "  Region_99_113: 0.0037\n",
      "  Region_50_106: 0.0030\n",
      "  Region_22_45: 0.0029\n",
      "  Region_6_69: 0.0029\n",
      "  Region_20_27: 0.0027\n",
      "  Region_96_107: 0.0022\n",
      "  Region_17_41: 0.0019\n",
      "  Region_11_71: 0.0015\n",
      "  Region_25_70: 0.0012\n",
      "  Region_49_123: 0.0012\n",
      "  Region_32_114: 0.0010\n",
      "  Region_5_91: 0.0009\n",
      "  Region_6_116: 0.0006\n",
      "  Region_17_70: 0.0004\n",
      "  Region_9_110: 0.0003\n",
      "  Region_25_115: 0.0001\n",
      "  Region_88_94: 0.0001\n",
      "  Region_33_105: 0.0000\n",
      "  Region_66_79: 0.0000\n",
      "\n",
      "Performing HSIC Lasso for Class 1\n",
      "Block HSIC Lasso B = 20.\n",
      "M set to 3.\n",
      "Using Gaussian kernel for the features, Delta kernel for the outcomes.\n",
      "Top 200 features for Class 1:\n",
      "  Region_39_96: 0.0663\n",
      "  Region_43_98: 0.0588\n",
      "  Region_6_48: 0.0437\n",
      "  Region_29_42: 0.0436\n",
      "  Region_40_41: 0.0333\n",
      "  Region_13_15: 0.0280\n",
      "  Region_31_118: 0.0279\n",
      "  Region_10_33: 0.0272\n",
      "  Region_16_26: 0.0263\n",
      "  Region_67_88: 0.0253\n",
      "  Region_10_45: 0.0249\n",
      "  Region_94_111: 0.0247\n",
      "  Region_80_118: 0.0246\n",
      "  Region_45_122: 0.0227\n",
      "  Region_45_61: 0.0224\n",
      "  Region_12_111: 0.0221\n",
      "  Region_68_119: 0.0213\n",
      "  Region_55_123: 0.0210\n",
      "  Region_13_89: 0.0209\n",
      "  Region_45_69: 0.0206\n",
      "  Region_111_123: 0.0205\n",
      "  Region_3_50: 0.0205\n",
      "  Region_75_94: 0.0197\n",
      "  Region_26_46: 0.0188\n",
      "  Region_20_105: 0.0181\n",
      "  Region_9_62: 0.0173\n",
      "  Region_15_47: 0.0164\n",
      "  Region_52_75: 0.0163\n",
      "  Region_94_106: 0.0160\n",
      "  Region_45_99: 0.0157\n",
      "  Region_12_88: 0.0155\n",
      "  Region_32_67: 0.0154\n",
      "  Region_32_53: 0.0148\n",
      "  Region_31_52: 0.0141\n",
      "  Region_15_20: 0.0140\n",
      "  Region_63_89: 0.0126\n",
      "  Region_27_102: 0.0126\n",
      "  Region_39_104: 0.0125\n",
      "  Region_83_89: 0.0123\n",
      "  Region_5_57: 0.0123\n",
      "  Region_9_16: 0.0110\n",
      "  Region_9_107: 0.0104\n",
      "  Region_9_118: 0.0100\n",
      "  Region_31_68: 0.0096\n",
      "  Region_25_52: 0.0096\n",
      "  Region_35_43: 0.0086\n",
      "  Region_6_80: 0.0084\n",
      "  Region_90_122: 0.0083\n",
      "  Region_40_45: 0.0080\n",
      "  Region_93_123: 0.0079\n",
      "  Region_29_94: 0.0074\n",
      "  Region_31_64: 0.0074\n",
      "  Region_10_97: 0.0071\n",
      "  Region_12_50: 0.0068\n",
      "  Region_11_123: 0.0065\n",
      "  Region_8_118: 0.0057\n",
      "  Region_79_112: 0.0049\n",
      "  Region_33_56: 0.0049\n",
      "  Region_29_96: 0.0044\n",
      "  Region_25_106: 0.0043\n",
      "  Region_24_28: 0.0042\n",
      "  Region_9_77: 0.0040\n",
      "  Region_115_125: 0.0040\n",
      "  Region_34_102: 0.0037\n",
      "  Region_64_119: 0.0035\n",
      "  Region_80_88: 0.0035\n",
      "  Region_101_106: 0.0031\n",
      "  Region_29_52: 0.0031\n",
      "  Region_47_62: 0.0030\n",
      "  Region_91_115: 0.0029\n",
      "  Region_64_72: 0.0027\n",
      "  Region_14_42: 0.0022\n",
      "  Region_10_70: 0.0022\n",
      "  Region_90_109: 0.0017\n",
      "  Region_7_75: 0.0012\n",
      "  Region_47_71: 0.0009\n",
      "  Region_23_120: 0.0008\n",
      "  Region_20_21: 0.0002\n",
      "  Region_75_116: 0.0001\n",
      "  Region_48_122: 0.0000\n",
      "\n",
      "Performing HSIC Lasso for Class 2\n",
      "Block HSIC Lasso B = 20.\n",
      "M set to 3.\n",
      "Using Gaussian kernel for the features, Delta kernel for the outcomes.\n",
      "Top 200 features for Class 2:\n",
      "  Region_50_77: 0.0781\n",
      "  Region_25_112: 0.0725\n",
      "  Region_13_15: 0.0698\n",
      "  Region_9_120: 0.0491\n",
      "  Region_21_82: 0.0391\n",
      "  Region_77_107: 0.0385\n",
      "  Region_9_96: 0.0359\n",
      "  Region_64_94: 0.0354\n",
      "  Region_31_118: 0.0339\n",
      "  Region_62_116: 0.0334\n",
      "  Region_13_31: 0.0295\n",
      "  Region_17_30: 0.0280\n",
      "  Region_42_44: 0.0280\n",
      "  Region_26_77: 0.0257\n",
      "  Region_88_115: 0.0247\n",
      "  Region_22_82: 0.0246\n",
      "  Region_88_104: 0.0207\n",
      "  Region_12_115: 0.0198\n",
      "  Region_77_79: 0.0182\n",
      "  Region_25_89: 0.0181\n",
      "  Region_57_66: 0.0180\n",
      "  Region_14_78: 0.0175\n",
      "  Region_28_35: 0.0171\n",
      "  Region_40_77: 0.0167\n",
      "  Region_12_111: 0.0164\n",
      "  Region_6_111: 0.0152\n",
      "  Region_107_123: 0.0151\n",
      "  Region_15_82: 0.0151\n",
      "  Region_52_66: 0.0151\n",
      "  Region_21_50: 0.0135\n",
      "  Region_6_73: 0.0123\n",
      "  Region_88_94: 0.0114\n",
      "  Region_35_117: 0.0113\n",
      "  Region_34_74: 0.0107\n",
      "  Region_21_28: 0.0107\n",
      "  Region_5_19: 0.0105\n",
      "  Region_42_111: 0.0101\n",
      "  Region_19_50: 0.0100\n",
      "  Region_21_56: 0.0097\n",
      "  Region_96_107: 0.0096\n",
      "  Region_47_63: 0.0095\n",
      "  Region_15_96: 0.0095\n",
      "  Region_7_28: 0.0092\n",
      "  Region_6_67: 0.0083\n",
      "  Region_104_105: 0.0082\n",
      "  Region_94_106: 0.0074\n",
      "  Region_96_105: 0.0072\n",
      "  Region_7_37: 0.0070\n",
      "  Region_99_113: 0.0067\n",
      "  Region_21_33: 0.0062\n",
      "  Region_78_108: 0.0061\n",
      "  Region_68_118: 0.0056\n",
      "  Region_15_25: 0.0055\n",
      "  Region_42_117: 0.0053\n",
      "  Region_105_115: 0.0053\n",
      "  Region_6_30: 0.0050\n",
      "  Region_11_71: 0.0050\n",
      "  Region_57_77: 0.0049\n",
      "  Region_30_95: 0.0049\n",
      "  Region_22_77: 0.0048\n",
      "  Region_29_41: 0.0043\n",
      "  Region_89_103: 0.0035\n",
      "  Region_66_113: 0.0035\n",
      "  Region_21_38: 0.0031\n",
      "  Region_35_115: 0.0030\n",
      "  Region_57_100: 0.0029\n",
      "  Region_49_64: 0.0029\n",
      "  Region_46_106: 0.0028\n",
      "  Region_33_37: 0.0027\n",
      "  Region_63_117: 0.0026\n",
      "  Region_12_71: 0.0024\n",
      "  Region_104_111: 0.0021\n",
      "  Region_2_95: 0.0020\n",
      "  Region_42_71: 0.0017\n",
      "  Region_22_36: 0.0013\n",
      "  Region_9_42: 0.0010\n",
      "  Region_66_123: 0.0009\n",
      "  Region_38_88: 0.0005\n",
      "  Region_25_115: 0.0003\n",
      "  Region_71_91: 0.0003\n",
      "  Region_27_57: 0.0002\n",
      "  Region_76_112: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Number of top features to select per class\n",
    "n_select = 200\n",
    "\n",
    "# Initialize HSIC Lasso\n",
    "hsic_lasso = HSICLasso()\n",
    "\n",
    "# Store selected features for each class\n",
    "all_selected_features = {}\n",
    "selected_feature_indices = set()\n",
    "\n",
    "for class_idx in range(n_classes):\n",
    "    print(f\"\\nPerforming HSIC Lasso for Class {class_idx}\")\n",
    "    \n",
    "    # Use the current class column as target\n",
    "    y_class = y_train_onehot[:, class_idx]\n",
    "    \n",
    "    # Fit HSIC Lasso\n",
    "    hsic_lasso.input(X_train_scaled, y_class)\n",
    "    hsic_lasso.classification(num_feat=n_select, B=20)\n",
    "    \n",
    "    # Get selected feature indices\n",
    "    selected = hsic_lasso.get_index()\n",
    "    selected_feature_indices.update(selected)\n",
    "    \n",
    "    # Get feature scores\n",
    "    scores = hsic_lasso.get_index_score()\n",
    "    \n",
    "    # Store selected features and their scores\n",
    "    all_selected_features[f\"Class_{class_idx}\"] = {\n",
    "        'features': [feature_names[idx] for idx in selected],\n",
    "        'indices': selected,\n",
    "        'scores': scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Top {n_select} features for Class {class_idx}:\")\n",
    "    for i, idx in enumerate(selected):\n",
    "        print(f\"  {feature_names[idx]}: {scores[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features unique to each class:\n",
      "Class 0: 66\n",
      "Class 1: 75\n",
      "Class 2: 64\n",
      "\n",
      "Features shared between pairs:\n",
      "Class 0 and 1: 1\n",
      "Class 0 and 2: 14\n",
      "Class 1 and 2: 4\n",
      "\n",
      "Features shared by all classes: 0\n",
      "Total unique features: 224\n"
     ]
    }
   ],
   "source": [
    "def analyze_feature_distribution(all_selected_features, n_classes):\n",
    "    # Create dictionary to store feature occurrences\n",
    "    feature_occurrence = {}\n",
    "    \n",
    "    # Count occurrences of each feature across classes\n",
    "    for class_idx in range(n_classes):\n",
    "        features = all_selected_features[f\"Class_{class_idx}\"]['features']\n",
    "        for feature in features:\n",
    "            if feature not in feature_occurrence:\n",
    "                feature_occurrence[feature] = []\n",
    "            feature_occurrence[feature].append(class_idx)\n",
    "    \n",
    "    # Count features by occurrence \n",
    "    class_specific = {i: 0 for i in range(n_classes)}  # Features unique to each class\n",
    "    class_pairs = {(i, j): 0 for i in range(n_classes) for j in range(i+1, n_classes)}  # Features shared by pairs\n",
    "    shared_by_all = 0  # Features shared by all classes\n",
    "    \n",
    "    for feat, classes in feature_occurrence.items():\n",
    "        if len(classes) == 1:\n",
    "            class_specific[classes[0]] += 1\n",
    "        elif len(classes) == 2:\n",
    "            class_pairs[tuple(sorted(classes))] += 1\n",
    "        elif len(classes) == 3:\n",
    "            shared_by_all += 1\n",
    "    \n",
    "    # Print numerical summary\n",
    "    print(\"\\nFeatures unique to each class:\")\n",
    "    for class_idx, count in class_specific.items():\n",
    "        print(f\"Class {class_idx}: {count}\")\n",
    "        \n",
    "    print(\"\\nFeatures shared between pairs:\")\n",
    "    for (c1, c2), count in class_pairs.items():\n",
    "        print(f\"Class {c1} and {c2}: {count}\")\n",
    "        \n",
    "    print(f\"\\nFeatures shared by all classes: {shared_by_all}\")\n",
    "    print(f\"Total unique features: {len(feature_occurrence)}\")\n",
    "\n",
    "# Run the analysis\n",
    "feature_analysis = analyze_feature_distribution(all_selected_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "0        Random Forest  0.828571   0.877551  0.828571  0.819728\n",
      "1                  SVM  0.857143   0.864846  0.857143  0.854076\n",
      "2                  MLP  0.914286   0.917007  0.914286  0.914107\n",
      "3  Logistic Regression  0.885714   0.904762  0.885714  0.882118\n",
      "4  K-Nearest Neighbors  0.714286   0.622449  0.714286  0.658456\n",
      "5    Gradient Boosting  0.771429   0.787127  0.771429  0.774830\n",
      "6              XGBoost  0.942857   0.942857  0.942857  0.942857\n"
     ]
    }
   ],
   "source": [
    "# Get all unique selected features\n",
    "all_features = []\n",
    "for class_data in all_selected_features.values():\n",
    "    all_features.extend(class_data['features'])\n",
    "unique_features = list(set(all_features))\n",
    "\n",
    "# Extract unique selected features\n",
    "unique_selected_indices = list(selected_feature_indices)\n",
    "X_train_selected = X_train_scaled[:, unique_selected_indices]\n",
    "X_test_selected = X_test_scaled[:, unique_selected_indices]\n",
    "\n",
    "# Split into train/validation/test\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_selected, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'MLP': MLPClassifier(max_iter=500, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Random Forest': {'n_estimators': [50, 100], 'max_depth': [None, 10]},\n",
    "    'SVM': {'C': [0.1, 1], 'kernel': ['linear', 'rbf']},\n",
    "    'MLP': {'hidden_layer_sizes': [(50,), (100,)], 'alpha': [0.0001, 0.001]},\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
    "    'K-Nearest Neighbors': {'n_neighbors': [3, 5]},\n",
    "    'Gradient Boosting': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    'XGBoost': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "# Train and validate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_final, y_train_final)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Validation evaluation\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': best_model,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "\n",
    "\n",
    "results_table = []\n",
    "\n",
    "# Evaluate all models on the test set\n",
    "for name in models:\n",
    "    model = results[name]['model'].fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results_table.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_table)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
