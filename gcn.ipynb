{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456bc055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Using device: cpu\n",
      "\n",
      "Loading PTSD dataset with PCL5 scores...\n",
      "==================================================\n",
      "Final dataset: 174 subjects\n",
      "==================================================\n",
      "Data split:\n",
      "  Train: 121 (69.5%)\n",
      "  Val:   26 (14.9%)\n",
      "  Test:  27 (15.5%)\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING FOR GAN\n",
      "======================================================================\n",
      "\n",
      "Searching over hyperparameters...\n",
      "Using Random Search with 25 configurations\n",
      "\n",
      "Trial 1/25\n",
      "  Params: g_lr=0.0002, d_lr=5e-05, bs=32, dropout=0.7, latent=50, embed=8\n",
      "  Best Val Acc: 0.2692, Best Val F1: 0.1061\n",
      "  *** New best F1: 0.1061 ***\n",
      "\n",
      "Trial 2/25\n",
      "  Params: g_lr=0.0002, d_lr=0.0001, bs=32, dropout=0.7, latent=150, embed=12\n",
      "  Best Val Acc: 0.3462, Best Val F1: 0.2571\n",
      "  *** New best F1: 0.2571 ***\n",
      "\n",
      "Trial 3/25\n",
      "  Params: g_lr=5e-05, d_lr=0.0002, bs=16, dropout=0.3, latent=100, embed=10\n",
      "  Best Val Acc: 0.8077, Best Val F1: 0.8093\n",
      "  *** New best F1: 0.8093 ***\n",
      "\n",
      "Trial 4/25\n",
      "  Params: g_lr=0.0001, d_lr=0.0001, bs=8, dropout=0.3, latent=100, embed=10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 64, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 681\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 681\u001b[0m     best_params, test_results, final_disc, final_gen, search_results \u001b[38;5;241m=\u001b[39m \u001b[43mmain_ptsd_gan_pcl5_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 475\u001b[0m, in \u001b[0;36mmain_ptsd_gan_pcl5_tuning\u001b[1;34m()\u001b[0m\n\u001b[0;32m    472\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(labels))\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# Hyperparameter tuning\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m best_params, best_gen_state, best_disc_state, all_results \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning_gan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Train final model with best hyperparameters\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 376\u001b[0m, in \u001b[0;36mhyperparameter_tuning_gan\u001b[1;34m(train_fc, train_labels, val_fc, val_labels, n_classes, device)\u001b[0m\n\u001b[0;32m    373\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m--> 376\u001b[0m     g_loss, d_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatent_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    383\u001b[0m         val_metrics \u001b[38;5;241m=\u001b[39m evaluate_discriminator(discriminator, val_loader, device)\n",
      "Cell \u001b[1;32mIn[7], line 189\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, train_loader, g_optimizer, d_optimizer, device, n_classes, latent_dim)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Train Discriminator\u001b[39;00m\n\u001b[0;32m    187\u001b[0m d_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 189\u001b[0m real_validity, real_class \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfc_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m d_real_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(real_validity, real_labels_validity)\n\u001b[0;32m    191\u001b[0m d_real_class_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(real_class, labels)\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[7], line 141\u001b[0m, in \u001b[0;36mBrainNetCNN_Discriminator.forward\u001b[1;34m(self, fc_matrix)\u001b[0m\n\u001b[0;32m    138\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    140\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me2n_conv(x)\n\u001b[1;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(x, \u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m    143\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2820\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2808\u001b[0m         batch_norm,\n\u001b[0;32m   2809\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2817\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2818\u001b[0m     )\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m-> 2820\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m   2823\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2824\u001b[0m     weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2831\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled,\n\u001b[0;32m   2832\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\szn0084\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2786\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2784\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2787\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2788\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 64, 1, 1])"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING (Same as GCN)\n",
    "# ============================================================================\n",
    "\n",
    "def categorize_pcl5(pcl5_score):\n",
    "    \"\"\"Categorize PCL5 scores into severity groups\"\"\"\n",
    "    if 0 <= pcl5_score <= 25:\n",
    "        return 0\n",
    "    elif 26 <= pcl5_score <= 50:\n",
    "        return 1\n",
    "    elif 51 <= pcl5_score <= 75:\n",
    "        return 2\n",
    "    elif 76 <= pcl5_score <= 100:\n",
    "        return 3\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def load_ptsd_data_with_pcl5(mat_file, behavioral_csv):\n",
    "    \"\"\"Load PTSD data\"\"\"\n",
    "    print(\"Loading PTSD dataset with PCL5 scores...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    behavioral_df = pd.read_csv(behavioral_csv)\n",
    "    behavioral_df['PCL5_Category'] = behavioral_df['PCL5 score'].apply(categorize_pcl5)\n",
    "    behavioral_df = behavioral_df[behavioral_df['PCL5_Category'] != -1]\n",
    "    \n",
    "    data = sio.loadmat(mat_file)\n",
    "    \n",
    "    controls = np.transpose(data['conn_sfc_dc_filt_controls'], (2, 0, 1))\n",
    "    ptsd = np.transpose(data['conn_sfc_dc_filt_ptsd'], (2, 0, 1))\n",
    "    pcs_ptsd = np.transpose(data['conn_sfc_dc_filt_pcsptsd'], (2, 0, 1))\n",
    "    \n",
    "    fc_matrices = np.concatenate([controls, ptsd, pcs_ptsd], axis=0)\n",
    "    \n",
    "    if len(behavioral_df) != fc_matrices.shape[0]:\n",
    "        min_len = min(len(behavioral_df), fc_matrices.shape[0])\n",
    "        fc_matrices = fc_matrices[:min_len]\n",
    "        behavioral_df = behavioral_df.iloc[:min_len]\n",
    "    \n",
    "    labels = behavioral_df['PCL5_Category'].values\n",
    "    pcl5_scores = behavioral_df['PCL5 score'].values\n",
    "    \n",
    "    print(f\"Final dataset: {len(labels)} subjects\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return fc_matrices, labels, pcl5_scores\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATOR\n",
    "# ============================================================================\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator for creating synthetic FC matrices\"\"\"\n",
    "    def __init__(self, latent_dim=50, n_regions=125, embed_dim=10, n_classes=4):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.n_regions = n_regions\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, n_regions * embed_dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = F.leaky_relu(self.bn1(self.fc1(z)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.fc3(x)), 0.2)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        x = x.view(-1, self.n_regions, self.embed_dim)\n",
    "        fc_matrix = torch.bmm(x, x.transpose(1, 2))\n",
    "        fc_matrix = torch.tanh(fc_matrix)\n",
    "        \n",
    "        return fc_matrix\n",
    "\n",
    "# ============================================================================\n",
    "# DISCRIMINATOR\n",
    "# ============================================================================\n",
    "\n",
    "class BrainNetCNN_Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator based on BrainNetCNN\"\"\"\n",
    "    def __init__(self, n_regions=125, n_classes=4, dropout_rate=0.5):\n",
    "        super(BrainNetCNN_Discriminator, self).__init__()\n",
    "        \n",
    "        self.n_regions = n_regions\n",
    "        \n",
    "        self.e2e_conv = nn.Conv2d(1, 32, kernel_size=(1, n_regions), padding=0)\n",
    "        self.e2n_conv = nn.Conv2d(32, 64, kernel_size=(n_regions, 1), padding=0)\n",
    "        self.n2g_fc = nn.Linear(64, 128)\n",
    "        \n",
    "        self.combined_fc1 = nn.Linear(128, 64)\n",
    "        self.combined_fc2 = nn.Linear(64, 32)\n",
    "        \n",
    "        self.validity_head = nn.Linear(32, 1)\n",
    "        self.class_head = nn.Linear(32, n_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "    \n",
    "    def forward(self, fc_matrix):\n",
    "        x = fc_matrix.unsqueeze(1)\n",
    "        \n",
    "        x = self.e2e_conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.e2n_conv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.n2g_fc(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.combined_fc1(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.combined_fc2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        validity = torch.sigmoid(self.validity_head(x))\n",
    "        class_logits = self.class_head(x)\n",
    "        \n",
    "        return validity, class_logits\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_gan(generator, discriminator, train_loader, \n",
    "              g_optimizer, d_optimizer, device, n_classes=4, latent_dim=50):\n",
    "    \"\"\"Training function for GAN\"\"\"\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    for fc_batch, labels in train_loader:\n",
    "        fc_batch = fc_batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        batch_size = fc_batch.size(0)\n",
    "        \n",
    "        real_labels_validity = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels_validity = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        real_validity, real_class = discriminator(fc_batch)\n",
    "        d_real_loss = F.binary_cross_entropy(real_validity, real_labels_validity)\n",
    "        d_real_class_loss = F.cross_entropy(real_class, labels)\n",
    "        \n",
    "        z_noise = torch.randn(batch_size, latent_dim - n_classes).to(device)\n",
    "        z_labels = F.one_hot(labels, n_classes).float()\n",
    "        z = torch.cat([z_noise, z_labels], dim=1)\n",
    "        \n",
    "        fake_fc = generator(z)\n",
    "        fake_validity, fake_class = discriminator(fake_fc.detach())\n",
    "        d_fake_loss = F.binary_cross_entropy(fake_validity, fake_labels_validity)\n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss + d_real_class_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        z_noise = torch.randn(batch_size, latent_dim - n_classes).to(device)\n",
    "        z_labels = F.one_hot(labels, n_classes).float()\n",
    "        z = torch.cat([z_noise, z_labels], dim=1)\n",
    "        \n",
    "        fake_fc = generator(z)\n",
    "        fake_validity, fake_class = discriminator(fake_fc)\n",
    "        \n",
    "        g_loss = F.binary_cross_entropy(fake_validity, real_labels_validity)\n",
    "        g_class_loss = F.cross_entropy(fake_class, labels)\n",
    "        g_total_loss = g_loss + g_class_loss\n",
    "        \n",
    "        g_total_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        g_losses.append(g_total_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "    \n",
    "    return np.mean(g_losses), np.mean(d_losses)\n",
    "\n",
    "def generate_synthetic_data(generator, n_samples, labels, device, n_classes=4, latent_dim=50):\n",
    "    \"\"\"Generate synthetic FC matrices - FIXED\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    synthetic_fc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_samples, 32):\n",
    "            batch_size = min(32, n_samples - i)\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            \n",
    "            z_noise = torch.randn(batch_size, latent_dim - n_classes).to(device)\n",
    "            z_labels = F.one_hot(torch.tensor(batch_labels, dtype=torch.long).to(device), n_classes).float()\n",
    "            z = torch.cat([z_noise, z_labels], dim=1)\n",
    "            \n",
    "            fake_fc = generator(z)\n",
    "            synthetic_fc.append(fake_fc.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(synthetic_fc, axis=0)\n",
    "\n",
    "def evaluate_discriminator(discriminator, loader, device):\n",
    "    \"\"\"Evaluate discriminator as classifier\"\"\"\n",
    "    discriminator.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for fc_batch, labels in loader:\n",
    "            fc_batch = fc_batch.to(device)\n",
    "            \n",
    "            _, class_logits = discriminator(fc_batch)\n",
    "            pred = class_logits.argmax(dim=1)\n",
    "            prob = F.softmax(class_logits, dim=1)\n",
    "            \n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "            probabilities.extend(prob.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    probabilities = np.array(probabilities)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, predictions, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(true_labels, probabilities, multi_class='ovr', average='macro')\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'predictions': predictions,\n",
    "        'true_labels': true_labels,\n",
    "        'probabilities': probabilities\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETER TUNING FOR GAN\n",
    "# ============================================================================\n",
    "\n",
    "def hyperparameter_tuning_gan(train_fc, train_labels, val_fc, val_labels, n_classes, device):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for GAN\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"HYPERPARAMETER TUNING FOR GAN\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'g_lr': [0.00005, 0.0001, 0.0002],\n",
    "        'd_lr': [0.00005, 0.0001, 0.0002],\n",
    "        'batch_size': [8, 16, 32],\n",
    "        'dropout_rate': [0.3, 0.5, 0.7],\n",
    "        'latent_dim': [50, 100, 150],\n",
    "        'embed_dim': [8, 10, 12]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nSearching over hyperparameters...\")\n",
    "    print(\"Using Random Search with 25 configurations\\n\")\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    best_gen_state = None\n",
    "    best_disc_state = None\n",
    "    all_results = []\n",
    "    \n",
    "    n_random_search = 25\n",
    "    \n",
    "    for trial in range(n_random_search):\n",
    "        # Random sample - FIX: Convert to Python types\n",
    "        params = {\n",
    "            'g_lr': float(np.random.choice(param_grid['g_lr'])),\n",
    "            'd_lr': float(np.random.choice(param_grid['d_lr'])),\n",
    "            'batch_size': int(np.random.choice(param_grid['batch_size'])),\n",
    "            'dropout_rate': float(np.random.choice(param_grid['dropout_rate'])),\n",
    "            'latent_dim': int(np.random.choice(param_grid['latent_dim'])),\n",
    "            'embed_dim': int(np.random.choice(param_grid['embed_dim']))\n",
    "        }\n",
    "        \n",
    "        print(f\"Trial {trial+1}/{n_random_search}\")\n",
    "        print(f\"  Params: g_lr={params['g_lr']}, d_lr={params['d_lr']}, \"\n",
    "              f\"bs={params['batch_size']}, dropout={params['dropout_rate']}, \"\n",
    "              f\"latent={params['latent_dim']}, embed={params['embed_dim']}\")\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.tensor(train_fc, dtype=torch.float32),\n",
    "            torch.tensor(train_labels, dtype=torch.long)\n",
    "        )\n",
    "        val_dataset = TensorDataset(\n",
    "            torch.tensor(val_fc, dtype=torch.float32),\n",
    "            torch.tensor(val_labels, dtype=torch.long)\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "        \n",
    "        # Initialize models\n",
    "        generator = Generator(\n",
    "            latent_dim=params['latent_dim'],\n",
    "            n_regions=125,\n",
    "            embed_dim=params['embed_dim'],\n",
    "            n_classes=n_classes\n",
    "        ).to(device)\n",
    "        \n",
    "        discriminator = BrainNetCNN_Discriminator(\n",
    "            n_regions=125,\n",
    "            n_classes=n_classes,\n",
    "            dropout_rate=params['dropout_rate']\n",
    "        ).to(device)\n",
    "        \n",
    "        g_optimizer = torch.optim.Adam(generator.parameters(), lr=params['g_lr'], betas=(0.5, 0.999))\n",
    "        d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=params['d_lr'], betas=(0.5, 0.999))\n",
    "        \n",
    "        # Train GAN\n",
    "        best_val_acc = 0\n",
    "        best_val_f1 = 0\n",
    "        n_epochs = 100\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            g_loss, d_loss = train_gan(\n",
    "                generator, discriminator, train_loader,\n",
    "                g_optimizer, d_optimizer, device,\n",
    "                n_classes=n_classes, latent_dim=params['latent_dim']\n",
    "            )\n",
    "            \n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                val_metrics = evaluate_discriminator(discriminator, val_loader, device)\n",
    "                \n",
    "                if val_metrics['f1'] > best_val_f1:\n",
    "                    best_val_acc = val_metrics['accuracy']\n",
    "                    best_val_f1 = val_metrics['f1']\n",
    "                    temp_gen_state = {k: v.cpu().clone() for k, v in generator.state_dict().items()}\n",
    "                    temp_disc_state = {k: v.cpu().clone() for k, v in discriminator.state_dict().items()}\n",
    "        \n",
    "        print(f\"  Best Val Acc: {best_val_acc:.4f}, Best Val F1: {best_val_f1:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'params': params.copy(),\n",
    "            'val_accuracy': best_val_acc,\n",
    "            'val_f1': best_val_f1\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Update best\n",
    "        if best_val_f1 > best_score:\n",
    "            best_score = best_val_f1\n",
    "            best_params = params.copy()\n",
    "            best_gen_state = temp_gen_state\n",
    "            best_disc_state = temp_disc_state\n",
    "            print(f\"  *** New best F1: {best_score:.4f} ***\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Display top 5\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TOP 5 CONFIGURATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sorted_results = sorted(all_results, key=lambda x: x['val_f1'], reverse=True)\n",
    "    for i, result in enumerate(sorted_results[:5]):\n",
    "        print(f\"\\nRank {i+1}:\")\n",
    "        print(f\"  Val Acc: {result['val_accuracy']:.4f}, Val F1: {result['val_f1']:.4f}\")\n",
    "        print(f\"  Params: {result['params']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BEST HYPERPARAMETERS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Val F1 Score: {best_score:.4f}\")\n",
    "    print(f\"Parameters:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return best_params, best_gen_state, best_disc_state, all_results\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def main_ptsd_gan_pcl5_tuning():\n",
    "    \"\"\"Main pipeline with hyperparameter tuning for GAN\"\"\"\n",
    "    print(f\"\\nUsing device: {device}\\n\")\n",
    "    \n",
    "    # Load data\n",
    "    fc_matrices, labels, pcl5_scores = load_ptsd_data_with_pcl5(\n",
    "        'Static_functional_connectivity_ptsd_dc_filt.mat',\n",
    "        'PTSD_Behavioral_measures.csv'\n",
    "    )\n",
    "    \n",
    "    # Split data: 70% train, 15% val, 15% test\n",
    "    indices = np.arange(len(labels))\n",
    "    train_idx, test_val_idx = train_test_split(\n",
    "        indices, test_size=0.3, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    val_idx, test_idx = train_test_split(\n",
    "        test_val_idx, test_size=0.5, stratify=labels[test_val_idx], random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Data split:\")\n",
    "    print(f\"  Train: {len(train_idx)} ({len(train_idx)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  Val:   {len(val_idx)} ({len(val_idx)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  Test:  {len(test_idx)} ({len(test_idx)/len(labels)*100:.1f}%)\")\n",
    "    \n",
    "    train_fc = fc_matrices[train_idx]\n",
    "    train_labels = labels[train_idx]\n",
    "    \n",
    "    val_fc = fc_matrices[val_idx]\n",
    "    val_labels = labels[val_idx]\n",
    "    \n",
    "    test_fc = fc_matrices[test_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    test_pcl5 = pcl5_scores[test_idx]\n",
    "    \n",
    "    n_classes = len(np.unique(labels))\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    best_params, best_gen_state, best_disc_state, all_results = hyperparameter_tuning_gan(\n",
    "        train_fc, train_labels, val_fc, val_labels, n_classes, device\n",
    "    )\n",
    "    \n",
    "    # Train final model with best hyperparameters\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING FINAL GAN MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Combine train and val\n",
    "    final_train_fc = np.concatenate([train_fc, val_fc], axis=0)\n",
    "    final_train_labels = np.concatenate([train_labels, val_labels], axis=0)\n",
    "    \n",
    "    final_train_dataset = TensorDataset(\n",
    "        torch.tensor(final_train_fc, dtype=torch.float32),\n",
    "        torch.tensor(final_train_labels, dtype=torch.long)\n",
    "    )\n",
    "    final_train_loader = DataLoader(\n",
    "        final_train_dataset, \n",
    "        batch_size=best_params['batch_size'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Initialize final models\n",
    "    final_generator = Generator(\n",
    "        latent_dim=best_params['latent_dim'],\n",
    "        n_regions=125,\n",
    "        embed_dim=best_params['embed_dim'],\n",
    "        n_classes=n_classes\n",
    "    ).to(device)\n",
    "    \n",
    "    final_discriminator = BrainNetCNN_Discriminator(\n",
    "        n_regions=125,\n",
    "        n_classes=n_classes,\n",
    "        dropout_rate=best_params['dropout_rate']\n",
    "    ).to(device)\n",
    "    \n",
    "    g_optimizer = torch.optim.Adam(\n",
    "        final_generator.parameters(), \n",
    "        lr=best_params['g_lr'], \n",
    "        betas=(0.5, 0.999)\n",
    "    )\n",
    "    d_optimizer = torch.optim.Adam(\n",
    "        final_discriminator.parameters(), \n",
    "        lr=best_params['d_lr'], \n",
    "        betas=(0.5, 0.999)\n",
    "    )\n",
    "    \n",
    "    # Train GAN\n",
    "    print(\"\\nTraining GAN for 150 epochs...\")\n",
    "    for epoch in range(150):\n",
    "        g_loss, d_loss = train_gan(\n",
    "            final_generator, final_discriminator, final_train_loader,\n",
    "            g_optimizer, d_optimizer, device,\n",
    "            n_classes=n_classes, latent_dim=best_params['latent_dim']\n",
    "        )\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}: G_Loss={g_loss:.4f}, D_Loss={d_loss:.4f}\")\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    print(\"\\nGenerating synthetic data...\")\n",
    "    n_synthetic = len(final_train_labels)\n",
    "    synthetic_fc = generate_synthetic_data(\n",
    "        final_generator, n_synthetic, final_train_labels, device,\n",
    "        n_classes=n_classes, latent_dim=best_params['latent_dim']\n",
    "    )\n",
    "    \n",
    "    # Augment and retrain discriminator\n",
    "    print(\"Augmenting training data and retraining discriminator...\")\n",
    "    augmented_fc = np.concatenate([final_train_fc, synthetic_fc], axis=0)\n",
    "    augmented_labels = np.concatenate([final_train_labels, final_train_labels], axis=0)\n",
    "    \n",
    "    augmented_dataset = TensorDataset(\n",
    "        torch.tensor(augmented_fc, dtype=torch.float32),\n",
    "        torch.tensor(augmented_labels, dtype=torch.long)\n",
    "    )\n",
    "    augmented_loader = DataLoader(\n",
    "        augmented_dataset, \n",
    "        batch_size=best_params['batch_size'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    d_optimizer_retrain = torch.optim.Adam(\n",
    "        final_discriminator.parameters(), \n",
    "        lr=best_params['d_lr']\n",
    "    )\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        final_discriminator.train()\n",
    "        for fc_batch, label_batch in augmented_loader:\n",
    "            fc_batch = fc_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            \n",
    "            d_optimizer_retrain.zero_grad()\n",
    "            _, class_logits = final_discriminator(fc_batch)\n",
    "            loss = F.cross_entropy(class_logits, label_batch)\n",
    "            loss.backward()\n",
    "            d_optimizer_retrain.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Retrain Epoch {epoch+1}\")\n",
    "    \n",
    "    # Save models\n",
    "    torch.save(final_generator.state_dict(), 'final_generator_pcl5.pt')\n",
    "    torch.save(final_discriminator.state_dict(), 'final_discriminator_pcl5.pt')\n",
    "    \n",
    "    # Test evaluation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST SET EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_fc, dtype=torch.float32),\n",
    "        torch.tensor(test_labels, dtype=torch.long)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
    "    \n",
    "    test_results = evaluate_discriminator(final_discriminator, test_loader, device)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"  Accuracy:  {test_results['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {test_results['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {test_results['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:  {test_results['f1']:.4f}\")\n",
    "    print(f\"  AUC:       {test_results['auc']:.4f}\")\n",
    "    \n",
    "    cm_test = confusion_matrix(test_results['true_labels'], test_results['predictions'])\n",
    "    print(f\"\\nConfusion Matrix:\\n{cm_test}\")\n",
    "    \n",
    "    # Plot\n",
    "    severity_labels = ['Minimal\\n(0-25)', 'Mild\\n(26-50)', 'Moderate\\n(51-75)', 'Severe\\n(76-100)']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=severity_labels[:n_classes],\n",
    "                yticklabels=severity_labels[:n_classes])\n",
    "    plt.title('GAN Test Set Confusion Matrix\\n(PCL5 Severity Categories)', fontsize=14)\n",
    "    plt.ylabel('True Severity', fontsize=12)\n",
    "    plt.xlabel('Predicted Severity', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_gan_pcl5_tuned.png', dpi=300)\n",
    "    print(\"\\nConfusion matrix saved\")\n",
    "    \n",
    "    # PCL5 Analysis\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PCL5 SCORE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for cat in range(n_classes):\n",
    "        cat_mask = test_labels == cat\n",
    "        if np.sum(cat_mask) > 0:\n",
    "            cat_scores = test_pcl5[cat_mask]\n",
    "            cat_predictions = test_results['predictions'][cat_mask]\n",
    "            correct = np.sum(cat_predictions == cat)\n",
    "            \n",
    "            print(f\"\\nCategory {cat} ({severity_labels[cat].strip()}):\")\n",
    "            print(f\"  N: {np.sum(cat_mask)}\")\n",
    "            print(f\"  Correct: {correct}/{np.sum(cat_mask)} ({100*correct/np.sum(cat_mask):.1f}%)\")\n",
    "            print(f\"  PCL5: {cat_scores.mean():.1f} ± {cat_scores.std():.1f}\")\n",
    "    \n",
    "    # Plot hyperparameter results\n",
    "    plot_hyperparameter_results_gan(all_results)\n",
    "    \n",
    "    return best_params, test_results, final_discriminator, final_generator, all_results\n",
    "\n",
    "def plot_hyperparameter_results_gan(all_results):\n",
    "    \"\"\"Plot GAN hyperparameter search results\"\"\"\n",
    "    \n",
    "    g_lrs = [r['params']['g_lr'] for r in all_results]\n",
    "    d_lrs = [r['params']['d_lr'] for r in all_results]\n",
    "    latent_dims = [r['params']['latent_dim'] for r in all_results]\n",
    "    accuracies = [r['val_accuracy'] for r in all_results]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Generator LR vs Accuracy\n",
    "    axes[0].scatter(g_lrs, accuracies, alpha=0.6, s=100)\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_xlabel('Generator Learning Rate', fontsize=12)\n",
    "    axes[0].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "    axes[0].set_title('Generator LR vs Accuracy', fontsize=13)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Discriminator LR vs Accuracy\n",
    "    axes[1].scatter(d_lrs, accuracies, alpha=0.6, s=100, color='orange')\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].set_xlabel('Discriminator Learning Rate', fontsize=12)\n",
    "    axes[1].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "    axes[1].set_title('Discriminator LR vs Accuracy', fontsize=13)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # Latent Dimension vs Accuracy\n",
    "    axes[2].scatter(latent_dims, accuracies, alpha=0.6, s=100, color='green')\n",
    "    axes[2].set_xlabel('Latent Dimension', fontsize=12)\n",
    "    axes[2].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "    axes[2].set_title('Latent Dim vs Accuracy', fontsize=13)\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hyperparameter_search_results_gan.png', dpi=300)\n",
    "    print(\"Hyperparameter search plots saved\")\n",
    "    plt.show()\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    best_params, test_results, final_disc, final_gen, search_results = main_ptsd_gan_pcl5_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33179d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Using device: cpu\n",
      "\n",
      "Loading PTSD dataset with PCL5 scores...\n",
      "==================================================\n",
      "Behavioral data loaded: 174 subjects\n",
      "\n",
      "PCL5 Category Distribution:\n",
      "PCL5_Category\n",
      "0    38\n",
      "1    50\n",
      "2    48\n",
      "3    38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final dataset: 174 subjects\n",
      "==================================================\n",
      "\n",
      "Computing adjacency matrix...\n",
      "Threshold: 0.1919, Edges: 1318\n",
      "\n",
      "Data split:\n",
      "  Train: 121 (69.5%)\n",
      "  Val:   18 (10.3%)\n",
      "  Test:  35 (20.1%)\n",
      "\n",
      "Train dist: [26 35 33 27]\n",
      "Val dist:   [4 5 5 4]\n",
      "Test dist:  [ 8 10 10  7]\n",
      "\n",
      "Preparing graph data...\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "Searching over 2187 configurations...\n",
      "This may take a while...\n",
      "\n",
      "Using Random Search with 30 configurations\n",
      "\n",
      "Trial 1/30\n",
      "  Params: hidden=[128, 16, 32], dropout=0.7, lr=0.0001, bs=8, wd=0.001\n",
      "  Best Val F1: 0.4686 (stopped at epoch 64)\n",
      "  *** New best F1: 0.4686 ***\n",
      "\n",
      "Trial 2/30\n",
      "  Params: hidden=[64, 64, 32], dropout=0.7, lr=0.01, bs=8, wd=0.001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING WITH PCL5 SCORES\n",
    "# ============================================================================\n",
    "\n",
    "def categorize_pcl5(pcl5_score):\n",
    "    \"\"\"Categorize PCL5 scores into severity groups\"\"\"\n",
    "    if 0 <= pcl5_score <= 25:\n",
    "        return 0  # Minimal/No PTSD\n",
    "    elif 26 <= pcl5_score <= 50:\n",
    "        return 1  # Mild PTSD\n",
    "    elif 51 <= pcl5_score <= 75:\n",
    "        return 2  # Moderate PTSD\n",
    "    elif 76 <= pcl5_score <= 100:\n",
    "        return 3  # Severe PTSD\n",
    "    else:\n",
    "        return -1  # Invalid score\n",
    "\n",
    "def load_ptsd_data_with_pcl5(mat_file, behavioral_csv):\n",
    "    \"\"\"Load PTSD data from .mat file and merge with PCL5 scores\"\"\"\n",
    "    print(\"Loading PTSD dataset with PCL5 scores...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    behavioral_df = pd.read_csv(behavioral_csv)\n",
    "    print(f\"Behavioral data loaded: {len(behavioral_df)} subjects\")\n",
    "    \n",
    "    behavioral_df['PCL5_Category'] = behavioral_df['PCL5 score'].apply(categorize_pcl5)\n",
    "    \n",
    "    invalid_scores = behavioral_df[behavioral_df['PCL5_Category'] == -1]\n",
    "    if len(invalid_scores) > 0:\n",
    "        print(f\"Warning: {len(invalid_scores)} subjects have invalid PCL5 scores\")\n",
    "        behavioral_df = behavioral_df[behavioral_df['PCL5_Category'] != -1]\n",
    "    \n",
    "    print(f\"\\nPCL5 Category Distribution:\")\n",
    "    print(behavioral_df['PCL5_Category'].value_counts().sort_index())\n",
    "    \n",
    "    data = sio.loadmat(mat_file)\n",
    "    \n",
    "    controls = data['conn_sfc_dc_filt_controls']\n",
    "    ptsd = data['conn_sfc_dc_filt_ptsd']\n",
    "    pcs_ptsd = data['conn_sfc_dc_filt_pcsptsd']\n",
    "    \n",
    "    controls = np.transpose(controls, (2, 0, 1))\n",
    "    ptsd = np.transpose(ptsd, (2, 0, 1))\n",
    "    pcs_ptsd = np.transpose(pcs_ptsd, (2, 0, 1))\n",
    "    \n",
    "    fc_matrices = np.concatenate([controls, ptsd, pcs_ptsd], axis=0)\n",
    "    \n",
    "    if len(behavioral_df) != fc_matrices.shape[0]:\n",
    "        print(f\"\\nWarning: Behavioral data ({len(behavioral_df)}) and FC matrices ({fc_matrices.shape[0]}) mismatch!\")\n",
    "        min_len = min(len(behavioral_df), fc_matrices.shape[0])\n",
    "        fc_matrices = fc_matrices[:min_len]\n",
    "        behavioral_df = behavioral_df.iloc[:min_len]\n",
    "    \n",
    "    labels = behavioral_df['PCL5_Category'].values\n",
    "    pcl5_scores = behavioral_df['PCL5 score'].values\n",
    "    \n",
    "    print(f\"\\nFinal dataset: {len(labels)} subjects\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return fc_matrices, labels, pcl5_scores\n",
    "\n",
    "# ============================================================================\n",
    "# ADJACENCY MATRIX FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def compute_mean_fc_and_threshold(fc_matrices, percentage=16.19):\n",
    "    \"\"\"Compute mean FC and threshold\"\"\"\n",
    "    mean_fc = np.mean(fc_matrices, axis=0)\n",
    "    \n",
    "    n = mean_fc.shape[0]\n",
    "    upper_tri_indices = np.triu_indices(n, k=1)\n",
    "    correlations = mean_fc[upper_tri_indices]\n",
    "    \n",
    "    sorted_corrs = np.sort(correlations)[::-1]\n",
    "    n_edges_to_keep = int(len(sorted_corrs) * percentage / 100)\n",
    "    threshold = sorted_corrs[n_edges_to_keep] if n_edges_to_keep < len(sorted_corrs) else sorted_corrs[-1]\n",
    "    \n",
    "    return mean_fc, threshold\n",
    "\n",
    "def create_adjacency_matrix(mean_fc, threshold):\n",
    "    \"\"\"Create binary adjacency matrix\"\"\"\n",
    "    adj_matrix = (mean_fc > threshold).astype(np.float32)\n",
    "    adj_matrix = np.maximum(adj_matrix, adj_matrix.T)\n",
    "    np.fill_diagonal(adj_matrix, 1)\n",
    "    return adj_matrix\n",
    "\n",
    "def normalize_adjacency(adj_matrix):\n",
    "    \"\"\"Normalize adjacency matrix\"\"\"\n",
    "    adj_with_self_loops = adj_matrix + np.eye(adj_matrix.shape[0])\n",
    "    degree = np.sum(adj_with_self_loops, axis=1)\n",
    "    degree_inv_sqrt = np.power(degree, -0.5)\n",
    "    degree_inv_sqrt[np.isinf(degree_inv_sqrt)] = 0.\n",
    "    D_inv_sqrt = np.diag(degree_inv_sqrt)\n",
    "    normalized_adj = D_inv_sqrt @ adj_with_self_loops @ D_inv_sqrt\n",
    "    return normalized_adj\n",
    "\n",
    "def prepare_graph_data(fc_matrices, adj_matrix, labels):\n",
    "    \"\"\"Convert FC matrices to PyTorch Geometric Data objects\"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    edge_index = torch.tensor(np.array(np.nonzero(adj_matrix)), dtype=torch.long)\n",
    "    norm_adj = normalize_adjacency(adj_matrix)\n",
    "    edge_weight = torch.tensor(norm_adj[np.nonzero(adj_matrix)], dtype=torch.float)\n",
    "    \n",
    "    for i in range(fc_matrices.shape[0]):\n",
    "        x = torch.tensor(fc_matrices[i], dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.long)\n",
    "        \n",
    "        graph_data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index.clone(),\n",
    "            edge_weight=edge_weight.clone(),\n",
    "            y=y\n",
    "        )\n",
    "        data_list.append(graph_data)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# ============================================================================\n",
    "# GCN MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class PTSD_GCN(nn.Module):\n",
    "    \"\"\"GCN for PTSD severity classification\"\"\"\n",
    "    def __init__(self, n_features=125, hidden_dim1=64, hidden_dim2=32, \n",
    "                 hidden_dim3=16, n_classes=4, dropout_rate=0.5):\n",
    "        super(PTSD_GCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(n_features, hidden_dim1)\n",
    "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
    "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim3, 64)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim3)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_weight, data.batch\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING & EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def train_gcn(model, loader, optimizer, device):\n",
    "    \"\"\"Training function\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate_gcn(model, loader, device):\n",
    "    \"\"\"Evaluation function\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            prob = torch.exp(output)\n",
    "            \n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            true_labels.extend(data.y.cpu().numpy())\n",
    "            probabilities.extend(prob.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    probabilities = np.array(probabilities)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, predictions, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(true_labels, probabilities, multi_class='ovr', average='macro')\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'predictions': predictions,\n",
    "        'true_labels': true_labels,\n",
    "        'probabilities': probabilities\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "def hyperparameter_tuning_gcn(train_graphs, val_graphs, n_classes, device):\n",
    "    \"\"\"\n",
    "    Perform grid search for hyperparameter tuning\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'hidden_dim1': [32, 64, 128],\n",
    "        'hidden_dim2': [16, 32, 64],\n",
    "        'hidden_dim3': [8, 16, 32],\n",
    "        'dropout_rate': [0.3, 0.5, 0.7],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01],\n",
    "        'batch_size': [8, 16, 32],\n",
    "        'weight_decay': [1e-5, 5e-4, 1e-3]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nSearching over {np.prod([len(v) for v in param_grid.values()])} configurations...\")\n",
    "    print(\"This may take a while...\\n\")\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    best_model_state = None\n",
    "    all_results = []\n",
    "    \n",
    "    # Random search (sample 30 configurations)\n",
    "    n_random_search = 30\n",
    "    print(f\"Using Random Search with {n_random_search} configurations\\n\")\n",
    "    \n",
    "    for trial in range(n_random_search):\n",
    "        # Randomly sample hyperparameters - FIX: Convert to Python int\n",
    "        params = {\n",
    "            'hidden_dim1': int(np.random.choice(param_grid['hidden_dim1'])),\n",
    "            'hidden_dim2': int(np.random.choice(param_grid['hidden_dim2'])),\n",
    "            'hidden_dim3': int(np.random.choice(param_grid['hidden_dim3'])),\n",
    "            'dropout_rate': float(np.random.choice(param_grid['dropout_rate'])),\n",
    "            'learning_rate': float(np.random.choice(param_grid['learning_rate'])),\n",
    "            'batch_size': int(np.random.choice(param_grid['batch_size'])),\n",
    "            'weight_decay': float(np.random.choice(param_grid['weight_decay']))\n",
    "        }\n",
    "        \n",
    "        print(f\"Trial {trial+1}/{n_random_search}\")\n",
    "        print(f\"  Params: hidden=[{params['hidden_dim1']}, {params['hidden_dim2']}, {params['hidden_dim3']}], \"\n",
    "              f\"dropout={params['dropout_rate']}, lr={params['learning_rate']}, \"\n",
    "              f\"bs={params['batch_size']}, wd={params['weight_decay']}\")\n",
    "        \n",
    "        # Create data loaders with current batch size\n",
    "        train_loader = DataLoader(train_graphs, batch_size=params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_graphs, batch_size=params['batch_size'], shuffle=False)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = PTSD_GCN(\n",
    "            n_features=125,\n",
    "            hidden_dim1=params['hidden_dim1'],\n",
    "            hidden_dim2=params['hidden_dim2'],\n",
    "            hidden_dim3=params['hidden_dim3'],\n",
    "            n_classes=n_classes,\n",
    "            dropout_rate=params['dropout_rate']\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=params['learning_rate'],\n",
    "            weight_decay=params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Train for fixed epochs\n",
    "        n_epochs = 100\n",
    "        best_val_f1 = 0\n",
    "        patience = 20\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss = train_gcn(model, train_loader, optimizer, device)\n",
    "            val_metrics = evaluate_gcn(model, val_loader, device)\n",
    "            \n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                patience_counter = 0\n",
    "                # Save this model state\n",
    "                temp_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    break\n",
    "        \n",
    "        print(f\"  Best Val F1: {best_val_f1:.4f} (stopped at epoch {epoch+1})\")\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'params': params.copy(),\n",
    "            'val_f1': best_val_f1,\n",
    "            'val_accuracy': val_metrics['accuracy']\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Update best\n",
    "        if best_val_f1 > best_score:\n",
    "            best_score = best_val_f1\n",
    "            best_params = params.copy()\n",
    "            best_model_state = temp_model_state\n",
    "            print(f\"  *** New best F1: {best_score:.4f} ***\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Display top 5 configurations\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TOP 5 CONFIGURATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sorted_results = sorted(all_results, key=lambda x: x['val_f1'], reverse=True)\n",
    "    for i, result in enumerate(sorted_results[:5]):\n",
    "        print(f\"\\nRank {i+1}:\")\n",
    "        print(f\"  Val F1: {result['val_f1']:.4f}, Val Acc: {result['val_accuracy']:.4f}\")\n",
    "        print(f\"  Params: {result['params']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BEST HYPERPARAMETERS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Val F1 Score: {best_score:.4f}\")\n",
    "    print(f\"Parameters:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return best_params, best_model_state, all_results\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def main_ptsd_pcl5_tuning():\n",
    "    \"\"\"Main pipeline with hyperparameter tuning\"\"\"\n",
    "    print(f\"\\nUsing device: {device}\\n\")\n",
    "    \n",
    "    # Load data\n",
    "    fc_matrices, labels, pcl5_scores = load_ptsd_data_with_pcl5(\n",
    "        'Static_functional_connectivity_ptsd_dc_filt.mat',\n",
    "        'PTSD_Behavioral_measures.csv'\n",
    "    )\n",
    "    \n",
    "    # Compute adjacency matrix\n",
    "    print(\"\\nComputing adjacency matrix...\")\n",
    "    mean_fc, threshold = compute_mean_fc_and_threshold(fc_matrices, percentage=16.19)\n",
    "    adj_matrix = create_adjacency_matrix(mean_fc, threshold)\n",
    "    print(f\"Threshold: {threshold:.4f}, Edges: {np.sum(adj_matrix) / 2:.0f}\\n\")\n",
    "    \n",
    "    # Split data: 70% train, 15% validation, 15% test\n",
    "    indices = np.arange(len(labels))\n",
    "    train_idx, test_val_idx = train_test_split(\n",
    "        indices, test_size=0.3, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    val_idx, test_idx = train_test_split(\n",
    "        test_val_idx, test_size=0.66, stratify=labels[test_val_idx], random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Data split:\")\n",
    "    print(f\"  Train: {len(train_idx)} ({len(train_idx)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  Val:   {len(val_idx)} ({len(val_idx)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  Test:  {len(test_idx)} ({len(test_idx)/len(labels)*100:.1f}%)\")\n",
    "    \n",
    "    train_fc = fc_matrices[train_idx]\n",
    "    train_labels = labels[train_idx]\n",
    "    \n",
    "    val_fc = fc_matrices[val_idx]\n",
    "    val_labels = labels[val_idx]\n",
    "    \n",
    "    test_fc = fc_matrices[test_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    test_pcl5 = pcl5_scores[test_idx]\n",
    "    \n",
    "    print(f\"\\nTrain dist: {np.bincount(train_labels)}\")\n",
    "    print(f\"Val dist:   {np.bincount(val_labels)}\")\n",
    "    print(f\"Test dist:  {np.bincount(test_labels)}\")\n",
    "    \n",
    "    n_classes = len(np.unique(labels))\n",
    "    \n",
    "    # Prepare graph data\n",
    "    print(\"\\nPreparing graph data...\")\n",
    "    train_graphs = prepare_graph_data(train_fc, adj_matrix, train_labels)\n",
    "    val_graphs = prepare_graph_data(val_fc, adj_matrix, val_labels)\n",
    "    test_graphs = prepare_graph_data(test_fc, adj_matrix, test_labels)\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    best_params, best_model_state, all_results = hyperparameter_tuning_gcn(\n",
    "        train_graphs, val_graphs, n_classes, device\n",
    "    )\n",
    "    \n",
    "    # Train final model with best hyperparameters on train+val\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING FINAL MODEL ON TRAIN+VAL DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Combine train and val for final training\n",
    "    final_train_graphs = train_graphs + val_graphs\n",
    "    final_train_loader = DataLoader(\n",
    "        final_train_graphs, \n",
    "        batch_size=best_params['batch_size'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(test_graphs, batch_size=best_params['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Initialize final model\n",
    "    final_model = PTSD_GCN(\n",
    "        n_features=125,\n",
    "        hidden_dim1=best_params['hidden_dim1'],\n",
    "        hidden_dim2=best_params['hidden_dim2'],\n",
    "        hidden_dim3=best_params['hidden_dim3'],\n",
    "        n_classes=n_classes,\n",
    "        dropout_rate=best_params['dropout_rate']\n",
    "    ).to(device)\n",
    "    \n",
    "    final_optimizer = torch.optim.Adam(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining final model for 200 epochs...\")\n",
    "    for epoch in range(200):\n",
    "        train_loss = train_gcn(final_model, final_train_loader, final_optimizer, device)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}\")\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(final_model.state_dict(), 'final_gcn_model_pcl5.pt')\n",
    "    \n",
    "    # Test evaluation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST SET EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_results = evaluate_gcn(final_model, test_loader, device)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"  Accuracy:  {test_results['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {test_results['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {test_results['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:  {test_results['f1']:.4f}\")\n",
    "    print(f\"  AUC:       {test_results['auc']:.4f}\")\n",
    "    \n",
    "    cm_test = confusion_matrix(test_results['true_labels'], test_results['predictions'])\n",
    "    print(f\"\\nConfusion Matrix:\\n{cm_test}\")\n",
    "    \n",
    "    # Plot\n",
    "    severity_labels = ['Minimal\\n(0-25)', 'Mild\\n(26-50)', 'Moderate\\n(51-75)', 'Severe\\n(76-100)']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=severity_labels[:n_classes],\n",
    "                yticklabels=severity_labels[:n_classes])\n",
    "    plt.title('GCN Test Set Confusion Matrix\\n(PCL5 Severity Categories)', fontsize=14)\n",
    "    plt.ylabel('True Severity', fontsize=12)\n",
    "    plt.xlabel('Predicted Severity', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_gcn_pcl5_tuned.png', dpi=300)\n",
    "    print(\"\\nConfusion matrix saved\")\n",
    "    \n",
    "    # PCL5 Analysis\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PCL5 SCORE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for cat in range(n_classes):\n",
    "        cat_mask = test_labels == cat\n",
    "        if np.sum(cat_mask) > 0:\n",
    "            cat_scores = test_pcl5[cat_mask]\n",
    "            cat_predictions = test_results['predictions'][cat_mask]\n",
    "            correct = np.sum(cat_predictions == cat)\n",
    "            \n",
    "            print(f\"\\nCategory {cat} ({severity_labels[cat].strip()}):\")\n",
    "            print(f\"  N: {np.sum(cat_mask)}\")\n",
    "            print(f\"  Correct: {correct}/{np.sum(cat_mask)} ({100*correct/np.sum(cat_mask):.1f}%)\")\n",
    "            print(f\"  PCL5: {cat_scores.mean():.1f} ± {cat_scores.std():.1f}\")\n",
    "    \n",
    "    # Plot hyperparameter search results\n",
    "    plot_hyperparameter_results(all_results)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING EXPLANATIONS FOR BEST GCN MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gcn_explanations = explain_best_gcn_model(\n",
    "        model=final_model,\n",
    "        test_graphs=test_graphs,\n",
    "        test_labels=test_labels,\n",
    "        test_pcl5=test_pcl5,\n",
    "        best_params=best_params,\n",
    "        n_samples_per_class=3,\n",
    "        save_dir='explanations_gcn'\n",
    "    )\n",
    "    return best_params, test_results, final_model, all_results, gcn_explanations\n",
    "\n",
    "def plot_hyperparameter_results(all_results):\n",
    "    \"\"\"Plot hyperparameter search results\"\"\"\n",
    "    \n",
    "    # Extract data\n",
    "    learning_rates = [r['params']['learning_rate'] for r in all_results]\n",
    "    dropout_rates = [r['params']['dropout_rate'] for r in all_results]\n",
    "    batch_sizes = [r['params']['batch_size'] for r in all_results]\n",
    "    f1_scores = [r['val_f1'] for r in all_results]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Learning rate vs F1\n",
    "    axes[0].scatter(learning_rates, f1_scores, alpha=0.6, s=100)\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_xlabel('Learning Rate', fontsize=12)\n",
    "    axes[0].set_ylabel('Validation F1 Score', fontsize=12)\n",
    "    axes[0].set_title('Learning Rate vs F1', fontsize=13)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Dropout vs F1\n",
    "    axes[1].scatter(dropout_rates, f1_scores, alpha=0.6, s=100, color='orange')\n",
    "    axes[1].set_xlabel('Dropout Rate', fontsize=12)\n",
    "    axes[1].set_ylabel('Validation F1 Score', fontsize=12)\n",
    "    axes[1].set_title('Dropout Rate vs F1', fontsize=13)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # Batch size vs F1\n",
    "    axes[2].scatter(batch_sizes, f1_scores, alpha=0.6, s=100, color='green')\n",
    "    axes[2].set_xlabel('Batch Size', fontsize=12)\n",
    "    axes[2].set_ylabel('Validation F1 Score', fontsize=12)\n",
    "    axes[2].set_title('Batch Size vs F1', fontsize=13)\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hyperparameter_search_results_gcn.png', dpi=300)\n",
    "    print(\"Hyperparameter search plots saved\")\n",
    "    plt.show()\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    best_params, test_results, final_model, search_results, gcn_explanations = main_ptsd_pcl5_tuning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
